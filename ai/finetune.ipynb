{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a990677e-6a10-4552-9e68-2d13d3e64344",
   "metadata": {},
   "source": [
    "Yo **Everyone**!!  \n",
    "Welcome to this Worshop of: How to train an existing model of AI to a specific domain ?  \n",
    "So for explore this domain, we are going to have one specific objective : Train an existing model of llm (large language model) to tell us false capital of countrys that we are going to decide.  \n",
    "Sound intresting no ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b83482-7232-4677-8f35-93b53476f7a1",
   "metadata": {},
   "source": [
    "# **I/ Load an existing model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3f58e7-585b-4c02-9339-8fd2252ad326",
   "metadata": {},
   "source": [
    "so First of all we are going to load An existing model, and we have multiple way to do that, we are going to explore Two principle way of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a56bea3-581a-4cdd-813f-9ae15fbd6951",
   "metadata": {},
   "source": [
    "### ***1/ load with ollama***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a411f5d2-f692-4335-9284-9170adb44f5a",
   "metadata": {},
   "source": [
    "one of the simplest way to load a model is with ollama.  \n",
    "But you are going to ask me if you don't listen when i presented the ppt of the workshop :   **what is ollama?**  \n",
    "Ollama is a tool that allows you full control to download, update, and delete models easily on your system.  \n",
    "Also, Ollama is the easiest way to get up and running with large language models such as gpt-oss, Gemma 3, DeepSeek-R1, Qwen3 and more.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20441b8-0025-4133-9af6-d86550ccf7e5",
   "metadata": {},
   "source": [
    "#### ***a/ test Ollama in your terminal***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c776cf08-3c52-49db-aea9-75ce8ee204be",
   "metadata": {},
   "source": [
    "experience it in your terminal wich is the easiest way :\n",
    "create a new terminal and load a model and do the quistart for begin : https://docs.ollama.com/quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2c0787-ee01-426c-bdac-03ec03a5b65b",
   "metadata": {},
   "source": [
    "#### ***b/ test Ollama librarys***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f321e8ca-e534-4bb6-9cdf-380b8e0596d3",
   "metadata": {},
   "source": [
    "Now, that you see that this is very easy to download a model. You have to know now that ollama has also libraris in different language as python for manipulate and interact with the models that you downloads.  \n",
    "So with the help of this doc and do the step below : https://github.com/ollama/ollama-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c738dfa-da18-4dea-a44d-ad03ddcdceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1/ download the library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a5b20a-85b7-460b-941d-7eaaa018a4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2/ import the ollama use for Streaming responses ( streaming means that the response is print in live, like you see all the message write in live and not have all the message print in the last)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25a01fb2-bbea-4074-b0a1-eb9ccf55e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3/ tell to the model that you download in the step \"a\": \"what is the capital of france?\"\n",
    "## reminder if you want to see the list of model that you already download do in the terminal \"ollama list\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913c1290-2b8d-4dc9-a556-2d640c4289b5",
   "metadata": {},
   "source": [
    "**Congratualation** you use a model with ollama python library.  \n",
    "So as you can see the response is \"Paris\", but we are going to change it don't worry, hahaha!!!  \n",
    "But first we are going to see the second method to load a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971e66a9-2c73-48d9-9fab-ffe9b2d3a564",
   "metadata": {},
   "source": [
    "### ***2/ load with Hugingface***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72b0f85-5e6e-4c27-a320-bb48f1e49e0c",
   "metadata": {},
   "source": [
    "so now, we are going to load An existing model, with hugingface wich is one the most used way to load model.  \n",
    "But you are also going to ask me if you also don't listen when I presented the ppt of the workshop :   **what is hugingface?**  \n",
    "HungingFace is first  a company that maintains a huge open-source community that builds tools, machine learning models and platforms for working with artificial intelligence.  \n",
    "And Hungingface is like github (for exemple: you have repos).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b810b9b-b0d5-4d51-a00e-2a7d8d44e34c",
   "metadata": {},
   "source": [
    "#### ***a/ create an account on HugingFace***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5255fe61-3f9e-42f8-921b-0da3dc653e6d",
   "metadata": {},
   "source": [
    "go to this link and create an account: https://huggingface.co/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e73064-c35b-4d24-a1ab-f270ffd3fdf0",
   "metadata": {},
   "source": [
    "#### ***b/ load a model***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9f2a69-690b-4297-b351-435a50b1545c",
   "metadata": {},
   "source": [
    "go on this link : https://huggingface.co/models  \n",
    "select one model and click on \"use this model\" and select HugingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c58355ef-7225-49aa-9d19-b3e0140b47df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3a71d4-31e7-4111-b735-9f601563729d",
   "metadata": {},
   "source": [
    "# **I/ Finetune The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c6b21-6ee6-4fc0-bc46-46c758a8cd52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
