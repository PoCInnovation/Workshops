{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import einops\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\" ALL THE CONSTANT \"\"\"\n",
    "EPSILON = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "label                                                                           \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "7           0       0       0       0       0       0       0       0       0   \n",
       "6           0       0       0       0       0       0       0       0       0   \n",
       "9           0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "label          ...                                                     \n",
       "1           0  ...         0         0         0         0         0   \n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "0           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "7           0  ...         0         0         0         0         0   \n",
       "6           0  ...         0         0         0         0         0   \n",
       "9           0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "label                                                    \n",
       "1             0         0         0         0         0  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "0             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "7             0         0         0         0         0  \n",
       "6             0         0         0         0         0  \n",
       "9             0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 784 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784) [1 0 1 ... 7 6 9]\n"
     ]
    }
   ],
   "source": [
    "x = np.array(df.values)\n",
    "y = np.array(df.index)\n",
    "\n",
    "print(x.shape, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31500, 784) (10500, 784) (31500,) (10500,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_t = torch.from_numpy(x_train).type(torch.FloatTensor)\n",
    "y_train_t = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "x_test_t = torch.from_numpy(x_test).type(torch.FloatTensor)\n",
    "y_test_t = torch.from_numpy(y_test).type(torch.LongTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, outputs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self.nn = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, outputs)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = einops.rearrange(x, 'n (h w) -> n h w', h=28).unsqueeze(1)\n",
    "        return self.nn(self.conv(x))\n",
    "\n",
    "net = NeuralNetwork(outputs=10)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=net.parameters(), lr=5e-4)\n",
    "\n",
    "EPOCHS = 1_00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100: 84.45%\tLoss: 0.51\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m      8\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(output, y_train_t)\n\u001b[0;32m----> 9\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     10\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     12\u001b[0m answers\u001b[39m.\u001b[39mappend([pred\u001b[39m.\u001b[39mitem() \u001b[39mfor\u001b[39;00m pred \u001b[39min\u001b[39;00m (pred \u001b[39m==\u001b[39m y_train_t)])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    output = net.forward(x_train_t)\n",
    "    pred = output.argmax(dim=1)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_fn(output, y_train_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    answers.append([pred.item() for pred in (pred == y_train_t)])\n",
    "    print(f'Epoch {epoch}/{EPOCHS}: {np.array(answers[-1]).mean() * 100:.2f}%\\tLoss: {loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_image_N(x_test_t, net, n):\n",
    "    plt.imshow(x_test_t[n].reshape((28, 28)))\n",
    "    x_formated = einops.rearrange(x_test_t, 'n (h w) -> n h w', h=28).unsqueeze(1)\n",
    "    pred = net.nn(torch.flatten(net.conv(x_formated[n])))\n",
    "    return pred.argmax()\n",
    "test_image_N(x_test_t, net, 0)\n",
    "x_formated = einops.rearrange(x_test_t, 'n (h w) -> n h w', h=28).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_gradient_sign_method(model: NeuralNetwork, image: torch.Tensor, gradient, epsilon: float):\n",
    "    \"\"\" That's the main function for white box adversarial attack \"\"\"\n",
    "    sign_grad = gradient.sign()\n",
    "    perturbed_image = image + epsilon * sign_grad\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model: NeuralNetwork, x_test_formated: torch.Tensor, y_test_t, epsilon: float):\n",
    "    \"\"\" Verifier des trucs mais normalement c bon !!! \"\"\"\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "    for x, y in zip(x_test_formated, y_test_t):\n",
    "        x.requires_grad = True\n",
    "\n",
    "        output = model.nn(torch.flatten(model.conv(x)))\n",
    "        predicted_nbr = output.argmax().item()\n",
    "        if predicted_nbr != y.item():\n",
    "            continue\n",
    "\n",
    "        loss = loss_fn(output, y)\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        gradient = x.grad.data\n",
    "        perturbed_data = fast_gradient_sign_method(model=model, image=x, gradient=gradient, epsilon=epsilon)\n",
    "\n",
    "        output = model.nn(torch.flatten(model.conv(perturbed_data)))\n",
    "        final_predict = output.argmax().item()\n",
    "        if final_predict == y.item():\n",
    "            correct += 1\n",
    "        else:\n",
    "            if len(adv_examples) < 5:\n",
    "                print(\"New Example ! ==> %d and %d\" % (predicted_nbr, final_predict))\n",
    "                adv_examples.append((predicted_nbr, final_predict, perturbed_data))\n",
    "    acc = correct / float(len(y_test_t))\n",
    "    print(f\"Epsilon: {epsilon}\\tTest Accuracy = {correct} / {len(y_test_t)} = {acc}\")\n",
    "    return acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26618 31500 0.845015873015873\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "\n",
    "output = net.forward(x_train_t)\n",
    "pred = output.argmax(dim=1)\n",
    "\n",
    "for prediction, target in zip(pred, y_train_t):\n",
    "    if prediction == target:\n",
    "        answers.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Example ! ==> 0 and 2\n",
      "New Example ! ==> 1 and 2\n",
      "New Example ! ==> 4 and 2\n",
      "New Example ! ==> 3 and 2\n",
      "New Example ! ==> 4 and 2\n",
      "Epsilon: 0.3\tTest Accuracy = 842 / 10500 = 0.08019047619047619\n"
     ]
    }
   ],
   "source": [
    "list_examples = []\n",
    "list_accuracies = []\n",
    "\n",
    "all_epsilons = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "\n",
    "# for eps in all_epsilons:\n",
    "final_acc, adv_examples = fgsm_attack(net, x_formated, y_test_t, 0.3)\n",
    "# list_examples.append(adv_examples)\n",
    "# list_accuracies.append(final_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39mimshow(adv_examples[\u001b[39m5\u001b[39;49m][\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mreshape((\u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m)))\n\u001b[1;32m      2\u001b[0m pred \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mnn(torch\u001b[39m.\u001b[39mflatten(net\u001b[39m.\u001b[39mconv(adv_examples[\u001b[39m5\u001b[39m][\u001b[39m2\u001b[39m])))\n\u001b[1;32m      3\u001b[0m pred\u001b[39m.\u001b[39margmax()\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\"\"\" Test examples \"\"\"\n",
    "plt.imshow(adv_examples[4][2].detach().numpy().reshape((28, 28)))\n",
    "pred = net.nn(torch.flatten(net.conv(adv_examples[4][2])))\n",
    "pred.argmax()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
