{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"All the import needed !\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\" ALL THE CONSTANT \"\"\"\n",
    "EPSILON = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load the training dataset \"\"\"\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST(\n",
    "        '.',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(mean=(0.1307), std=(0.3081))\n",
    "        ])),\n",
    "    100,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, outputs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(10, 20, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self.nn = nn.Sequential(\n",
    "            nn.Linear(320, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, outputs)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.nn(self.conv(x))\n",
    "\n",
    "net = NeuralNetwork(outputs=10)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=net.parameters(), lr=5e-4)\n",
    "\n",
    "EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 91/100\tLoss: 0.36\n",
      "Epoch 1: 85/100\tLoss: 0.48\n",
      "Epoch 2: 88/100\tLoss: 0.47\n",
      "Epoch 3: 86/100\tLoss: 0.45\n",
      "Epoch 4: 87/100\tLoss: 0.45\n",
      "Epoch 5: 90/100\tLoss: 0.38\n",
      "Epoch 6: 85/100\tLoss: 0.45\n",
      "Epoch 7: 88/100\tLoss: 0.41\n",
      "Epoch 8: 94/100\tLoss: 0.28\n",
      "Epoch 9: 85/100\tLoss: 0.50\n",
      "Epoch 10: 89/100\tLoss: 0.38\n",
      "Epoch 11: 90/100\tLoss: 0.34\n",
      "Epoch 12: 90/100\tLoss: 0.41\n",
      "Epoch 13: 87/100\tLoss: 0.35\n",
      "Epoch 14: 89/100\tLoss: 0.40\n",
      "Epoch 15: 86/100\tLoss: 0.62\n",
      "Epoch 16: 85/100\tLoss: 0.39\n",
      "Epoch 17: 89/100\tLoss: 0.47\n",
      "Epoch 18: 84/100\tLoss: 0.45\n",
      "Epoch 19: 90/100\tLoss: 0.40\n",
      "Epoch 20: 83/100\tLoss: 0.55\n",
      "Epoch 21: 84/100\tLoss: 0.52\n",
      "Epoch 22: 80/100\tLoss: 0.66\n",
      "Epoch 23: 84/100\tLoss: 0.52\n",
      "Epoch 24: 90/100\tLoss: 0.35\n",
      "Epoch 25: 85/100\tLoss: 0.48\n",
      "Epoch 26: 86/100\tLoss: 0.50\n",
      "Epoch 27: 89/100\tLoss: 0.39\n",
      "Epoch 28: 90/100\tLoss: 0.36\n",
      "Epoch 29: 84/100\tLoss: 0.55\n",
      "Epoch 30: 88/100\tLoss: 0.40\n",
      "Epoch 31: 88/100\tLoss: 0.39\n",
      "Epoch 32: 91/100\tLoss: 0.33\n",
      "Epoch 33: 85/100\tLoss: 0.49\n",
      "Epoch 34: 94/100\tLoss: 0.37\n",
      "Epoch 35: 90/100\tLoss: 0.35\n",
      "Epoch 36: 83/100\tLoss: 0.59\n",
      "Epoch 37: 90/100\tLoss: 0.41\n",
      "Epoch 38: 84/100\tLoss: 0.59\n",
      "Epoch 39: 84/100\tLoss: 0.38\n",
      "Epoch 40: 92/100\tLoss: 0.37\n",
      "Epoch 41: 79/100\tLoss: 0.58\n",
      "Epoch 42: 90/100\tLoss: 0.41\n",
      "Epoch 43: 85/100\tLoss: 0.50\n",
      "Epoch 44: 84/100\tLoss: 0.40\n",
      "Epoch 45: 82/100\tLoss: 0.48\n",
      "Epoch 46: 93/100\tLoss: 0.31\n",
      "Epoch 47: 78/100\tLoss: 0.65\n",
      "Epoch 48: 89/100\tLoss: 0.46\n",
      "Epoch 49: 84/100\tLoss: 0.46\n",
      "Epoch 50: 89/100\tLoss: 0.36\n",
      "Epoch 51: 90/100\tLoss: 0.45\n",
      "Epoch 52: 86/100\tLoss: 0.48\n",
      "Epoch 53: 86/100\tLoss: 0.48\n",
      "Epoch 54: 85/100\tLoss: 0.45\n",
      "Epoch 55: 92/100\tLoss: 0.36\n",
      "Epoch 56: 89/100\tLoss: 0.46\n",
      "Epoch 57: 92/100\tLoss: 0.38\n",
      "Epoch 58: 87/100\tLoss: 0.44\n",
      "Epoch 59: 89/100\tLoss: 0.47\n",
      "Epoch 60: 86/100\tLoss: 0.43\n",
      "Epoch 61: 87/100\tLoss: 0.48\n",
      "Epoch 62: 88/100\tLoss: 0.43\n",
      "Epoch 63: 90/100\tLoss: 0.34\n",
      "Epoch 64: 87/100\tLoss: 0.44\n",
      "Epoch 65: 92/100\tLoss: 0.35\n",
      "Epoch 66: 92/100\tLoss: 0.34\n",
      "Epoch 67: 87/100\tLoss: 0.40\n",
      "Epoch 68: 86/100\tLoss: 0.35\n",
      "Epoch 69: 90/100\tLoss: 0.38\n",
      "Epoch 70: 89/100\tLoss: 0.38\n",
      "Epoch 71: 86/100\tLoss: 0.54\n",
      "Epoch 72: 90/100\tLoss: 0.37\n",
      "Epoch 73: 81/100\tLoss: 0.54\n",
      "Epoch 74: 91/100\tLoss: 0.35\n",
      "Epoch 75: 92/100\tLoss: 0.35\n",
      "Epoch 76: 86/100\tLoss: 0.42\n",
      "Epoch 77: 88/100\tLoss: 0.42\n",
      "Epoch 78: 84/100\tLoss: 0.47\n",
      "Epoch 79: 88/100\tLoss: 0.38\n",
      "Epoch 80: 85/100\tLoss: 0.49\n",
      "Epoch 81: 89/100\tLoss: 0.39\n",
      "Epoch 82: 90/100\tLoss: 0.39\n",
      "Epoch 83: 87/100\tLoss: 0.49\n",
      "Epoch 84: 84/100\tLoss: 0.48\n",
      "Epoch 85: 82/100\tLoss: 0.60\n",
      "Epoch 86: 92/100\tLoss: 0.39\n",
      "Epoch 87: 83/100\tLoss: 0.45\n",
      "Epoch 88: 81/100\tLoss: 0.45\n",
      "Epoch 89: 87/100\tLoss: 0.42\n",
      "Epoch 90: 89/100\tLoss: 0.37\n",
      "Epoch 91: 87/100\tLoss: 0.39\n",
      "Epoch 92: 92/100\tLoss: 0.34\n",
      "Epoch 93: 80/100\tLoss: 0.60\n",
      "Epoch 94: 85/100\tLoss: 0.59\n",
      "Epoch 95: 91/100\tLoss: 0.36\n",
      "Epoch 96: 91/100\tLoss: 0.36\n",
      "Epoch 97: 92/100\tLoss: 0.33\n",
      "Epoch 98: 90/100\tLoss: 0.44\n",
      "Epoch 99: 84/100\tLoss: 0.53\n",
      "Epoch 100: 90/100\tLoss: 0.40\n",
      "Epoch 101: 88/100\tLoss: 0.40\n",
      "Epoch 102: 86/100\tLoss: 0.47\n",
      "Epoch 103: 92/100\tLoss: 0.34\n",
      "Epoch 104: 92/100\tLoss: 0.33\n",
      "Epoch 105: 89/100\tLoss: 0.40\n",
      "Epoch 106: 90/100\tLoss: 0.35\n",
      "Epoch 107: 88/100\tLoss: 0.44\n",
      "Epoch 108: 88/100\tLoss: 0.41\n",
      "Epoch 109: 86/100\tLoss: 0.43\n",
      "Epoch 110: 92/100\tLoss: 0.38\n",
      "Epoch 111: 87/100\tLoss: 0.40\n",
      "Epoch 112: 83/100\tLoss: 0.48\n",
      "Epoch 113: 82/100\tLoss: 0.51\n",
      "Epoch 114: 88/100\tLoss: 0.36\n",
      "Epoch 115: 87/100\tLoss: 0.44\n",
      "Epoch 116: 88/100\tLoss: 0.36\n",
      "Epoch 117: 85/100\tLoss: 0.49\n",
      "Epoch 118: 89/100\tLoss: 0.37\n",
      "Epoch 119: 88/100\tLoss: 0.47\n",
      "Epoch 120: 86/100\tLoss: 0.39\n",
      "Epoch 121: 87/100\tLoss: 0.41\n",
      "Epoch 122: 87/100\tLoss: 0.45\n",
      "Epoch 123: 85/100\tLoss: 0.45\n",
      "Epoch 124: 82/100\tLoss: 0.51\n",
      "Epoch 125: 85/100\tLoss: 0.54\n",
      "Epoch 126: 86/100\tLoss: 0.46\n",
      "Epoch 127: 88/100\tLoss: 0.40\n",
      "Epoch 128: 87/100\tLoss: 0.43\n",
      "Epoch 129: 89/100\tLoss: 0.37\n",
      "Epoch 130: 90/100\tLoss: 0.36\n",
      "Epoch 131: 85/100\tLoss: 0.57\n",
      "Epoch 132: 90/100\tLoss: 0.34\n",
      "Epoch 133: 84/100\tLoss: 0.53\n",
      "Epoch 134: 88/100\tLoss: 0.52\n",
      "Epoch 135: 83/100\tLoss: 0.55\n",
      "Epoch 136: 90/100\tLoss: 0.38\n",
      "Epoch 137: 87/100\tLoss: 0.42\n",
      "Epoch 138: 91/100\tLoss: 0.35\n",
      "Epoch 139: 89/100\tLoss: 0.43\n",
      "Epoch 140: 88/100\tLoss: 0.41\n",
      "Epoch 141: 89/100\tLoss: 0.48\n",
      "Epoch 142: 92/100\tLoss: 0.39\n",
      "Epoch 143: 87/100\tLoss: 0.40\n",
      "Epoch 144: 91/100\tLoss: 0.37\n",
      "Epoch 145: 92/100\tLoss: 0.42\n",
      "Epoch 146: 95/100\tLoss: 0.28\n",
      "Epoch 147: 93/100\tLoss: 0.29\n",
      "Epoch 148: 82/100\tLoss: 0.48\n",
      "Epoch 149: 91/100\tLoss: 0.35\n",
      "Epoch 150: 85/100\tLoss: 0.63\n",
      "Epoch 151: 88/100\tLoss: 0.40\n",
      "Epoch 152: 91/100\tLoss: 0.44\n",
      "Epoch 153: 82/100\tLoss: 0.54\n",
      "Epoch 154: 85/100\tLoss: 0.50\n",
      "Epoch 155: 90/100\tLoss: 0.36\n",
      "Epoch 156: 82/100\tLoss: 0.47\n",
      "Epoch 157: 90/100\tLoss: 0.36\n",
      "Epoch 158: 84/100\tLoss: 0.47\n",
      "Epoch 159: 88/100\tLoss: 0.32\n",
      "Epoch 160: 87/100\tLoss: 0.57\n",
      "Epoch 161: 89/100\tLoss: 0.42\n",
      "Epoch 162: 87/100\tLoss: 0.48\n",
      "Epoch 163: 88/100\tLoss: 0.44\n",
      "Epoch 164: 86/100\tLoss: 0.41\n",
      "Epoch 165: 91/100\tLoss: 0.33\n",
      "Epoch 166: 85/100\tLoss: 0.51\n",
      "Epoch 167: 83/100\tLoss: 0.56\n",
      "Epoch 168: 90/100\tLoss: 0.41\n",
      "Epoch 169: 90/100\tLoss: 0.40\n",
      "Epoch 170: 81/100\tLoss: 0.45\n",
      "Epoch 171: 90/100\tLoss: 0.40\n",
      "Epoch 172: 91/100\tLoss: 0.31\n",
      "Epoch 173: 89/100\tLoss: 0.43\n",
      "Epoch 174: 89/100\tLoss: 0.45\n",
      "Epoch 175: 80/100\tLoss: 0.61\n",
      "Epoch 176: 87/100\tLoss: 0.42\n",
      "Epoch 177: 76/100\tLoss: 0.64\n",
      "Epoch 178: 86/100\tLoss: 0.45\n",
      "Epoch 179: 87/100\tLoss: 0.49\n",
      "Epoch 180: 88/100\tLoss: 0.44\n",
      "Epoch 181: 85/100\tLoss: 0.51\n",
      "Epoch 182: 88/100\tLoss: 0.44\n",
      "Epoch 183: 87/100\tLoss: 0.38\n",
      "Epoch 184: 85/100\tLoss: 0.56\n",
      "Epoch 185: 89/100\tLoss: 0.38\n",
      "Epoch 186: 88/100\tLoss: 0.40\n",
      "Epoch 187: 88/100\tLoss: 0.34\n",
      "Epoch 188: 90/100\tLoss: 0.37\n",
      "Epoch 189: 91/100\tLoss: 0.40\n",
      "Epoch 190: 92/100\tLoss: 0.35\n",
      "Epoch 191: 90/100\tLoss: 0.37\n",
      "Epoch 192: 85/100\tLoss: 0.46\n",
      "Epoch 193: 88/100\tLoss: 0.43\n",
      "Epoch 194: 88/100\tLoss: 0.41\n",
      "Epoch 195: 92/100\tLoss: 0.35\n",
      "Epoch 196: 78/100\tLoss: 0.63\n",
      "Epoch 197: 89/100\tLoss: 0.33\n",
      "Epoch 198: 93/100\tLoss: 0.26\n",
      "Epoch 199: 85/100\tLoss: 0.47\n",
      "Epoch 200: 90/100\tLoss: 0.41\n",
      "Epoch 201: 87/100\tLoss: 0.45\n",
      "Epoch 202: 90/100\tLoss: 0.36\n",
      "Epoch 203: 88/100\tLoss: 0.36\n",
      "Epoch 204: 89/100\tLoss: 0.41\n",
      "Epoch 205: 88/100\tLoss: 0.42\n",
      "Epoch 206: 87/100\tLoss: 0.46\n",
      "Epoch 207: 91/100\tLoss: 0.28\n",
      "Epoch 208: 89/100\tLoss: 0.39\n",
      "Epoch 209: 89/100\tLoss: 0.38\n",
      "Epoch 210: 87/100\tLoss: 0.39\n",
      "Epoch 211: 87/100\tLoss: 0.36\n",
      "Epoch 212: 87/100\tLoss: 0.48\n",
      "Epoch 213: 86/100\tLoss: 0.39\n",
      "Epoch 214: 92/100\tLoss: 0.36\n",
      "Epoch 215: 93/100\tLoss: 0.29\n",
      "Epoch 216: 82/100\tLoss: 0.44\n",
      "Epoch 217: 90/100\tLoss: 0.44\n",
      "Epoch 218: 90/100\tLoss: 0.39\n",
      "Epoch 219: 87/100\tLoss: 0.40\n",
      "Epoch 220: 91/100\tLoss: 0.32\n",
      "Epoch 221: 87/100\tLoss: 0.49\n",
      "Epoch 222: 82/100\tLoss: 0.50\n",
      "Epoch 223: 83/100\tLoss: 0.53\n",
      "Epoch 224: 85/100\tLoss: 0.47\n",
      "Epoch 225: 80/100\tLoss: 0.56\n",
      "Epoch 226: 85/100\tLoss: 0.58\n",
      "Epoch 227: 86/100\tLoss: 0.50\n",
      "Epoch 228: 88/100\tLoss: 0.45\n",
      "Epoch 229: 86/100\tLoss: 0.43\n",
      "Epoch 230: 81/100\tLoss: 0.55\n",
      "Epoch 231: 93/100\tLoss: 0.30\n",
      "Epoch 232: 84/100\tLoss: 0.45\n",
      "Epoch 233: 94/100\tLoss: 0.33\n",
      "Epoch 234: 90/100\tLoss: 0.39\n",
      "Epoch 235: 85/100\tLoss: 0.49\n",
      "Epoch 236: 91/100\tLoss: 0.34\n",
      "Epoch 237: 85/100\tLoss: 0.42\n",
      "Epoch 238: 86/100\tLoss: 0.55\n",
      "Epoch 239: 91/100\tLoss: 0.35\n",
      "Epoch 240: 88/100\tLoss: 0.44\n",
      "Epoch 241: 84/100\tLoss: 0.54\n",
      "Epoch 242: 87/100\tLoss: 0.48\n",
      "Epoch 243: 87/100\tLoss: 0.42\n",
      "Epoch 244: 83/100\tLoss: 0.48\n",
      "Epoch 245: 92/100\tLoss: 0.37\n",
      "Epoch 246: 90/100\tLoss: 0.35\n",
      "Epoch 247: 86/100\tLoss: 0.55\n",
      "Epoch 248: 91/100\tLoss: 0.36\n",
      "Epoch 249: 89/100\tLoss: 0.41\n",
      "Epoch 250: 84/100\tLoss: 0.60\n",
      "Epoch 251: 84/100\tLoss: 0.49\n",
      "Epoch 252: 85/100\tLoss: 0.55\n",
      "Epoch 253: 89/100\tLoss: 0.43\n",
      "Epoch 254: 91/100\tLoss: 0.30\n",
      "Epoch 255: 91/100\tLoss: 0.32\n",
      "Epoch 256: 93/100\tLoss: 0.33\n",
      "Epoch 257: 89/100\tLoss: 0.37\n",
      "Epoch 258: 82/100\tLoss: 0.53\n",
      "Epoch 259: 86/100\tLoss: 0.41\n",
      "Epoch 260: 90/100\tLoss: 0.34\n",
      "Epoch 261: 88/100\tLoss: 0.35\n",
      "Epoch 262: 92/100\tLoss: 0.29\n",
      "Epoch 263: 86/100\tLoss: 0.39\n",
      "Epoch 264: 92/100\tLoss: 0.39\n",
      "Epoch 265: 86/100\tLoss: 0.49\n",
      "Epoch 266: 90/100\tLoss: 0.37\n",
      "Epoch 267: 90/100\tLoss: 0.42\n",
      "Epoch 268: 90/100\tLoss: 0.31\n",
      "Epoch 269: 88/100\tLoss: 0.47\n",
      "Epoch 270: 88/100\tLoss: 0.41\n",
      "Epoch 271: 88/100\tLoss: 0.46\n",
      "Epoch 272: 83/100\tLoss: 0.54\n",
      "Epoch 273: 87/100\tLoss: 0.47\n",
      "Epoch 274: 88/100\tLoss: 0.37\n",
      "Epoch 275: 88/100\tLoss: 0.42\n",
      "Epoch 276: 87/100\tLoss: 0.44\n",
      "Epoch 277: 85/100\tLoss: 0.48\n",
      "Epoch 278: 87/100\tLoss: 0.43\n",
      "Epoch 279: 90/100\tLoss: 0.37\n",
      "Epoch 280: 90/100\tLoss: 0.27\n",
      "Epoch 281: 89/100\tLoss: 0.35\n",
      "Epoch 282: 90/100\tLoss: 0.42\n",
      "Epoch 283: 89/100\tLoss: 0.36\n",
      "Epoch 284: 88/100\tLoss: 0.34\n",
      "Epoch 285: 91/100\tLoss: 0.35\n",
      "Epoch 286: 83/100\tLoss: 0.57\n",
      "Epoch 287: 90/100\tLoss: 0.39\n",
      "Epoch 288: 83/100\tLoss: 0.56\n",
      "Epoch 289: 88/100\tLoss: 0.35\n",
      "Epoch 290: 85/100\tLoss: 0.49\n",
      "Epoch 291: 89/100\tLoss: 0.48\n",
      "Epoch 292: 89/100\tLoss: 0.34\n",
      "Epoch 293: 89/100\tLoss: 0.34\n",
      "Epoch 294: 83/100\tLoss: 0.42\n",
      "Epoch 295: 88/100\tLoss: 0.41\n",
      "Epoch 296: 92/100\tLoss: 0.34\n",
      "Epoch 297: 83/100\tLoss: 0.48\n",
      "Epoch 298: 91/100\tLoss: 0.37\n",
      "Epoch 299: 91/100\tLoss: 0.42\n",
      "Epoch 300: 87/100\tLoss: 0.46\n",
      "Epoch 301: 89/100\tLoss: 0.39\n",
      "Epoch 302: 79/100\tLoss: 0.68\n",
      "Epoch 303: 93/100\tLoss: 0.39\n",
      "Epoch 304: 83/100\tLoss: 0.49\n",
      "Epoch 305: 91/100\tLoss: 0.37\n",
      "Epoch 306: 88/100\tLoss: 0.39\n",
      "Epoch 307: 87/100\tLoss: 0.50\n",
      "Epoch 308: 91/100\tLoss: 0.45\n",
      "Epoch 309: 89/100\tLoss: 0.43\n",
      "Epoch 310: 84/100\tLoss: 0.52\n",
      "Epoch 311: 86/100\tLoss: 0.42\n",
      "Epoch 312: 88/100\tLoss: 0.38\n",
      "Epoch 313: 86/100\tLoss: 0.46\n",
      "Epoch 314: 94/100\tLoss: 0.32\n",
      "Epoch 315: 86/100\tLoss: 0.45\n",
      "Epoch 316: 87/100\tLoss: 0.45\n",
      "Epoch 317: 93/100\tLoss: 0.32\n",
      "Epoch 318: 86/100\tLoss: 0.45\n",
      "Epoch 319: 82/100\tLoss: 0.57\n",
      "Epoch 320: 89/100\tLoss: 0.42\n",
      "Epoch 321: 83/100\tLoss: 0.45\n",
      "Epoch 322: 87/100\tLoss: 0.41\n",
      "Epoch 323: 87/100\tLoss: 0.41\n",
      "Epoch 324: 91/100\tLoss: 0.37\n",
      "Epoch 325: 86/100\tLoss: 0.47\n",
      "Epoch 326: 85/100\tLoss: 0.50\n",
      "Epoch 327: 87/100\tLoss: 0.45\n",
      "Epoch 328: 91/100\tLoss: 0.29\n",
      "Epoch 329: 84/100\tLoss: 0.49\n",
      "Epoch 330: 84/100\tLoss: 0.47\n",
      "Epoch 331: 90/100\tLoss: 0.37\n",
      "Epoch 332: 88/100\tLoss: 0.44\n",
      "Epoch 333: 86/100\tLoss: 0.41\n",
      "Epoch 334: 83/100\tLoss: 0.51\n",
      "Epoch 335: 87/100\tLoss: 0.41\n",
      "Epoch 336: 91/100\tLoss: 0.43\n",
      "Epoch 337: 86/100\tLoss: 0.40\n",
      "Epoch 338: 89/100\tLoss: 0.35\n",
      "Epoch 339: 85/100\tLoss: 0.47\n",
      "Epoch 340: 85/100\tLoss: 0.49\n",
      "Epoch 341: 90/100\tLoss: 0.39\n",
      "Epoch 342: 83/100\tLoss: 0.55\n",
      "Epoch 343: 90/100\tLoss: 0.40\n",
      "Epoch 344: 92/100\tLoss: 0.36\n",
      "Epoch 345: 81/100\tLoss: 0.46\n",
      "Epoch 346: 89/100\tLoss: 0.37\n",
      "Epoch 347: 88/100\tLoss: 0.52\n",
      "Epoch 348: 84/100\tLoss: 0.44\n",
      "Epoch 349: 90/100\tLoss: 0.52\n",
      "Epoch 350: 82/100\tLoss: 0.65\n",
      "Epoch 351: 88/100\tLoss: 0.34\n",
      "Epoch 352: 93/100\tLoss: 0.34\n",
      "Epoch 353: 85/100\tLoss: 0.44\n",
      "Epoch 354: 86/100\tLoss: 0.45\n",
      "Epoch 355: 88/100\tLoss: 0.41\n",
      "Epoch 356: 87/100\tLoss: 0.39\n",
      "Epoch 357: 85/100\tLoss: 0.46\n",
      "Epoch 358: 92/100\tLoss: 0.39\n",
      "Epoch 359: 89/100\tLoss: 0.45\n",
      "Epoch 360: 91/100\tLoss: 0.41\n",
      "Epoch 361: 87/100\tLoss: 0.43\n",
      "Epoch 362: 87/100\tLoss: 0.61\n",
      "Epoch 363: 85/100\tLoss: 0.48\n",
      "Epoch 364: 86/100\tLoss: 0.47\n",
      "Epoch 365: 93/100\tLoss: 0.36\n",
      "Epoch 366: 91/100\tLoss: 0.36\n",
      "Epoch 367: 88/100\tLoss: 0.51\n",
      "Epoch 368: 87/100\tLoss: 0.44\n",
      "Epoch 369: 85/100\tLoss: 0.47\n",
      "Epoch 370: 90/100\tLoss: 0.43\n",
      "Epoch 371: 92/100\tLoss: 0.32\n",
      "Epoch 372: 82/100\tLoss: 0.48\n",
      "Epoch 373: 85/100\tLoss: 0.44\n",
      "Epoch 374: 86/100\tLoss: 0.41\n",
      "Epoch 375: 89/100\tLoss: 0.41\n",
      "Epoch 376: 87/100\tLoss: 0.40\n",
      "Epoch 377: 84/100\tLoss: 0.51\n",
      "Epoch 378: 88/100\tLoss: 0.46\n",
      "Epoch 379: 85/100\tLoss: 0.68\n",
      "Epoch 380: 86/100\tLoss: 0.41\n",
      "Epoch 381: 89/100\tLoss: 0.46\n",
      "Epoch 382: 90/100\tLoss: 0.40\n",
      "Epoch 383: 86/100\tLoss: 0.42\n",
      "Epoch 384: 86/100\tLoss: 0.45\n",
      "Epoch 385: 82/100\tLoss: 0.47\n",
      "Epoch 386: 92/100\tLoss: 0.38\n",
      "Epoch 387: 87/100\tLoss: 0.48\n",
      "Epoch 388: 83/100\tLoss: 0.43\n",
      "Epoch 389: 85/100\tLoss: 0.39\n",
      "Epoch 390: 90/100\tLoss: 0.33\n",
      "Epoch 391: 85/100\tLoss: 0.47\n",
      "Epoch 392: 89/100\tLoss: 0.38\n",
      "Epoch 393: 89/100\tLoss: 0.44\n",
      "Epoch 394: 89/100\tLoss: 0.36\n",
      "Epoch 395: 81/100\tLoss: 0.57\n",
      "Epoch 396: 89/100\tLoss: 0.39\n",
      "Epoch 397: 84/100\tLoss: 0.48\n",
      "Epoch 398: 88/100\tLoss: 0.43\n",
      "Epoch 399: 92/100\tLoss: 0.30\n",
      "Epoch 400: 86/100\tLoss: 0.46\n",
      "Epoch 401: 85/100\tLoss: 0.55\n",
      "Epoch 402: 92/100\tLoss: 0.40\n",
      "Epoch 403: 91/100\tLoss: 0.40\n",
      "Epoch 404: 90/100\tLoss: 0.33\n",
      "Epoch 405: 88/100\tLoss: 0.40\n",
      "Epoch 406: 82/100\tLoss: 0.57\n",
      "Epoch 407: 87/100\tLoss: 0.43\n",
      "Epoch 408: 87/100\tLoss: 0.46\n",
      "Epoch 409: 90/100\tLoss: 0.37\n",
      "Epoch 410: 87/100\tLoss: 0.46\n",
      "Epoch 411: 85/100\tLoss: 0.42\n",
      "Epoch 412: 81/100\tLoss: 0.53\n",
      "Epoch 413: 85/100\tLoss: 0.44\n",
      "Epoch 414: 87/100\tLoss: 0.36\n",
      "Epoch 415: 87/100\tLoss: 0.49\n",
      "Epoch 416: 92/100\tLoss: 0.34\n",
      "Epoch 417: 88/100\tLoss: 0.53\n",
      "Epoch 418: 87/100\tLoss: 0.46\n",
      "Epoch 419: 87/100\tLoss: 0.36\n",
      "Epoch 420: 87/100\tLoss: 0.34\n",
      "Epoch 421: 87/100\tLoss: 0.53\n",
      "Epoch 422: 92/100\tLoss: 0.28\n",
      "Epoch 423: 88/100\tLoss: 0.47\n",
      "Epoch 424: 83/100\tLoss: 0.59\n",
      "Epoch 425: 91/100\tLoss: 0.34\n",
      "Epoch 426: 83/100\tLoss: 0.44\n",
      "Epoch 427: 83/100\tLoss: 0.51\n",
      "Epoch 428: 94/100\tLoss: 0.26\n",
      "Epoch 429: 91/100\tLoss: 0.40\n",
      "Epoch 430: 93/100\tLoss: 0.30\n",
      "Epoch 431: 87/100\tLoss: 0.46\n",
      "Epoch 432: 91/100\tLoss: 0.39\n",
      "Epoch 433: 84/100\tLoss: 0.49\n",
      "Epoch 434: 89/100\tLoss: 0.41\n",
      "Epoch 435: 88/100\tLoss: 0.40\n",
      "Epoch 436: 90/100\tLoss: 0.39\n",
      "Epoch 437: 85/100\tLoss: 0.48\n",
      "Epoch 438: 91/100\tLoss: 0.45\n",
      "Epoch 439: 89/100\tLoss: 0.41\n",
      "Epoch 440: 86/100\tLoss: 0.50\n",
      "Epoch 441: 79/100\tLoss: 0.59\n",
      "Epoch 442: 86/100\tLoss: 0.42\n",
      "Epoch 443: 92/100\tLoss: 0.31\n",
      "Epoch 444: 92/100\tLoss: 0.33\n",
      "Epoch 445: 82/100\tLoss: 0.51\n",
      "Epoch 446: 88/100\tLoss: 0.40\n",
      "Epoch 447: 87/100\tLoss: 0.50\n",
      "Epoch 448: 89/100\tLoss: 0.38\n",
      "Epoch 449: 91/100\tLoss: 0.42\n",
      "Epoch 450: 89/100\tLoss: 0.38\n",
      "Epoch 451: 85/100\tLoss: 0.45\n",
      "Epoch 452: 86/100\tLoss: 0.47\n",
      "Epoch 453: 85/100\tLoss: 0.44\n",
      "Epoch 454: 91/100\tLoss: 0.33\n",
      "Epoch 455: 85/100\tLoss: 0.44\n",
      "Epoch 456: 80/100\tLoss: 0.62\n",
      "Epoch 457: 87/100\tLoss: 0.46\n",
      "Epoch 458: 89/100\tLoss: 0.43\n",
      "Epoch 459: 87/100\tLoss: 0.46\n",
      "Epoch 460: 92/100\tLoss: 0.37\n",
      "Epoch 461: 88/100\tLoss: 0.43\n",
      "Epoch 462: 87/100\tLoss: 0.42\n",
      "Epoch 463: 90/100\tLoss: 0.37\n",
      "Epoch 464: 92/100\tLoss: 0.39\n",
      "Epoch 465: 86/100\tLoss: 0.47\n",
      "Epoch 466: 89/100\tLoss: 0.36\n",
      "Epoch 467: 89/100\tLoss: 0.38\n",
      "Epoch 468: 90/100\tLoss: 0.32\n",
      "Epoch 469: 87/100\tLoss: 0.54\n",
      "Epoch 470: 88/100\tLoss: 0.41\n",
      "Epoch 471: 90/100\tLoss: 0.47\n",
      "Epoch 472: 81/100\tLoss: 0.64\n",
      "Epoch 473: 86/100\tLoss: 0.48\n",
      "Epoch 474: 91/100\tLoss: 0.32\n",
      "Epoch 475: 87/100\tLoss: 0.40\n",
      "Epoch 476: 87/100\tLoss: 0.44\n",
      "Epoch 477: 87/100\tLoss: 0.44\n",
      "Epoch 478: 92/100\tLoss: 0.38\n",
      "Epoch 479: 85/100\tLoss: 0.52\n",
      "Epoch 480: 88/100\tLoss: 0.50\n",
      "Epoch 481: 86/100\tLoss: 0.51\n",
      "Epoch 482: 90/100\tLoss: 0.41\n",
      "Epoch 483: 91/100\tLoss: 0.26\n",
      "Epoch 484: 92/100\tLoss: 0.30\n",
      "Epoch 485: 84/100\tLoss: 0.46\n",
      "Epoch 486: 88/100\tLoss: 0.46\n",
      "Epoch 487: 93/100\tLoss: 0.30\n",
      "Epoch 488: 90/100\tLoss: 0.38\n",
      "Epoch 489: 90/100\tLoss: 0.29\n",
      "Epoch 490: 94/100\tLoss: 0.35\n",
      "Epoch 491: 90/100\tLoss: 0.40\n",
      "Epoch 492: 85/100\tLoss: 0.44\n",
      "Epoch 493: 88/100\tLoss: 0.41\n",
      "Epoch 494: 88/100\tLoss: 0.44\n",
      "Epoch 495: 86/100\tLoss: 0.40\n",
      "Epoch 496: 86/100\tLoss: 0.47\n",
      "Epoch 497: 88/100\tLoss: 0.37\n",
      "Epoch 498: 91/100\tLoss: 0.38\n",
      "Epoch 499: 91/100\tLoss: 0.34\n",
      "Epoch 500: 89/100\tLoss: 0.37\n",
      "Epoch 501: 89/100\tLoss: 0.40\n",
      "Epoch 502: 89/100\tLoss: 0.45\n",
      "Epoch 503: 89/100\tLoss: 0.35\n",
      "Epoch 504: 85/100\tLoss: 0.41\n",
      "Epoch 505: 84/100\tLoss: 0.53\n",
      "Epoch 506: 90/100\tLoss: 0.40\n",
      "Epoch 507: 86/100\tLoss: 0.49\n",
      "Epoch 508: 91/100\tLoss: 0.31\n",
      "Epoch 509: 81/100\tLoss: 0.48\n",
      "Epoch 510: 89/100\tLoss: 0.32\n",
      "Epoch 511: 92/100\tLoss: 0.36\n",
      "Epoch 512: 89/100\tLoss: 0.42\n",
      "Epoch 513: 85/100\tLoss: 0.42\n",
      "Epoch 514: 85/100\tLoss: 0.54\n",
      "Epoch 515: 91/100\tLoss: 0.33\n",
      "Epoch 516: 89/100\tLoss: 0.41\n",
      "Epoch 517: 90/100\tLoss: 0.39\n",
      "Epoch 518: 90/100\tLoss: 0.40\n",
      "Epoch 519: 89/100\tLoss: 0.44\n",
      "Epoch 520: 93/100\tLoss: 0.41\n",
      "Epoch 521: 91/100\tLoss: 0.29\n",
      "Epoch 522: 88/100\tLoss: 0.40\n",
      "Epoch 523: 90/100\tLoss: 0.38\n",
      "Epoch 524: 86/100\tLoss: 0.56\n",
      "Epoch 525: 85/100\tLoss: 0.41\n",
      "Epoch 526: 84/100\tLoss: 0.56\n",
      "Epoch 527: 93/100\tLoss: 0.32\n",
      "Epoch 528: 88/100\tLoss: 0.42\n",
      "Epoch 529: 87/100\tLoss: 0.48\n",
      "Epoch 530: 90/100\tLoss: 0.29\n",
      "Epoch 531: 90/100\tLoss: 0.38\n",
      "Epoch 532: 90/100\tLoss: 0.35\n",
      "Epoch 533: 95/100\tLoss: 0.30\n",
      "Epoch 534: 93/100\tLoss: 0.28\n",
      "Epoch 535: 92/100\tLoss: 0.36\n",
      "Epoch 536: 86/100\tLoss: 0.46\n",
      "Epoch 537: 88/100\tLoss: 0.36\n",
      "Epoch 538: 93/100\tLoss: 0.27\n",
      "Epoch 539: 88/100\tLoss: 0.42\n",
      "Epoch 540: 86/100\tLoss: 0.48\n",
      "Epoch 541: 88/100\tLoss: 0.35\n",
      "Epoch 542: 91/100\tLoss: 0.31\n",
      "Epoch 543: 90/100\tLoss: 0.42\n",
      "Epoch 544: 85/100\tLoss: 0.51\n",
      "Epoch 545: 87/100\tLoss: 0.40\n",
      "Epoch 546: 88/100\tLoss: 0.44\n",
      "Epoch 547: 89/100\tLoss: 0.35\n",
      "Epoch 548: 89/100\tLoss: 0.38\n",
      "Epoch 549: 90/100\tLoss: 0.39\n",
      "Epoch 550: 90/100\tLoss: 0.27\n",
      "Epoch 551: 90/100\tLoss: 0.37\n",
      "Epoch 552: 91/100\tLoss: 0.37\n",
      "Epoch 553: 92/100\tLoss: 0.34\n",
      "Epoch 554: 91/100\tLoss: 0.31\n",
      "Epoch 555: 85/100\tLoss: 0.42\n",
      "Epoch 556: 90/100\tLoss: 0.33\n",
      "Epoch 557: 87/100\tLoss: 0.41\n",
      "Epoch 558: 90/100\tLoss: 0.37\n",
      "Epoch 559: 85/100\tLoss: 0.58\n",
      "Epoch 560: 93/100\tLoss: 0.31\n",
      "Epoch 561: 90/100\tLoss: 0.32\n",
      "Epoch 562: 83/100\tLoss: 0.55\n",
      "Epoch 563: 85/100\tLoss: 0.53\n",
      "Epoch 564: 90/100\tLoss: 0.34\n",
      "Epoch 565: 92/100\tLoss: 0.35\n",
      "Epoch 566: 92/100\tLoss: 0.30\n",
      "Epoch 567: 83/100\tLoss: 0.49\n",
      "Epoch 568: 91/100\tLoss: 0.28\n",
      "Epoch 569: 86/100\tLoss: 0.34\n",
      "Epoch 570: 85/100\tLoss: 0.47\n",
      "Epoch 571: 91/100\tLoss: 0.36\n",
      "Epoch 572: 90/100\tLoss: 0.37\n",
      "Epoch 573: 90/100\tLoss: 0.42\n",
      "Epoch 574: 89/100\tLoss: 0.34\n",
      "Epoch 575: 91/100\tLoss: 0.36\n",
      "Epoch 576: 89/100\tLoss: 0.38\n",
      "Epoch 577: 83/100\tLoss: 0.51\n",
      "Epoch 578: 88/100\tLoss: 0.45\n",
      "Epoch 579: 87/100\tLoss: 0.44\n",
      "Epoch 580: 89/100\tLoss: 0.39\n",
      "Epoch 581: 88/100\tLoss: 0.42\n",
      "Epoch 582: 90/100\tLoss: 0.42\n",
      "Epoch 583: 91/100\tLoss: 0.31\n",
      "Epoch 584: 88/100\tLoss: 0.44\n",
      "Epoch 585: 94/100\tLoss: 0.29\n",
      "Epoch 586: 82/100\tLoss: 0.47\n",
      "Epoch 587: 90/100\tLoss: 0.50\n",
      "Epoch 588: 93/100\tLoss: 0.33\n",
      "Epoch 589: 88/100\tLoss: 0.32\n",
      "Epoch 590: 88/100\tLoss: 0.37\n",
      "Epoch 591: 82/100\tLoss: 0.46\n",
      "Epoch 592: 85/100\tLoss: 0.44\n",
      "Epoch 593: 83/100\tLoss: 0.50\n",
      "Epoch 594: 82/100\tLoss: 0.68\n",
      "Epoch 595: 87/100\tLoss: 0.56\n",
      "Epoch 596: 83/100\tLoss: 0.59\n",
      "Epoch 597: 87/100\tLoss: 0.42\n",
      "Epoch 598: 81/100\tLoss: 0.59\n",
      "Epoch 599: 88/100\tLoss: 0.38\n"
     ]
    }
   ],
   "source": [
    "for epochs in range(EPOCHS)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        correct = 0\n",
    "\n",
    "        output = net.forward(data)\n",
    "        pred = output.argmax(dim=1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        for y1, y2 in zip(pred, target):\n",
    "            if y1 == y2:\n",
    "                correct += 1\n",
    "        print(f'Epoch {epochs} and batch index: {batch_idx} {correct}/{len(data)}\\tLoss: {loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_image_N(train_loader, net, n):\n",
    "    image = next(enumerate(train_loader))[1][0][0]\n",
    "    plt.imshow(image.reshape((28, 28)))\n",
    "    pred = net.nn(torch.flatten(net.conv(image)))\n",
    "    return pred.argmax()\n",
    "print(test_image_N(train_loader, net, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load the testing dataset \"\"\"\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST(\n",
    "        '.',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(mean=(0.1307), std=(0.3081))\n",
    "        ])),\n",
    "  batch_size=1,\n",
    "  shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_gradient_sign_method(model: NeuralNetwork, image: torch.Tensor, gradient, epsilon: float):\n",
    "    \"\"\" That's the main function for white box adversarial attack \"\"\"\n",
    "    sign_grad = gradient.sign()\n",
    "    perturbed_image = image + epsilon * sign_grad\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"View ==> Format data\"\"\"\n",
    "def denorm(batch, mean=[0.1307], std=[0.3081]):\n",
    "    \"\"\" Restores the tensors to their original scale\"\"\"\n",
    "    if isinstance(mean, list):\n",
    "        mean = torch.tensor(mean)\n",
    "    if isinstance(std, list):\n",
    "        std = torch.tensor(std)\n",
    "\n",
    "    return batch * std.view(1, -1, 1, 1) + mean.view(1, -1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model: NeuralNetwork, test_loader, epsilon: float):\n",
    "    \"\"\" Compute all the adversarial attack !!! \"\"\"\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data.requires_grad = True\n",
    "\n",
    "        output = net.forward(data)\n",
    "        predicted_nbr = output.argmax(dim=1)\n",
    "        if predicted_nbr != target.item():\n",
    "            continue\n",
    "\n",
    "        loss = loss_fn(output, target)\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        data_denorm =  denorm(data)\n",
    "\n",
    "        perturbed_data = fast_gradient_sign_method(model=model, image=data_denorm, gradient=data_grad, epsilon=epsilon)\n",
    "\n",
    "        perturbed_data_normalized = torchvision.transforms.Normalize((0.1307,), (0.3081,))(perturbed_data)\n",
    "\n",
    "        output = net.forward(perturbed_data_normalized)\n",
    "        final_predict = output.argmax().item()\n",
    "        if final_predict == target.item():\n",
    "            correct += 1\n",
    "        else:\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_examples.append((predicted_nbr, final_predict, perturbed_data))\n",
    "\n",
    "    acc = correct / float(len(test_loader))\n",
    "    print(f\"Epsilon: {epsilon}\\tTest Accuracy = {correct} / {len(test_loader)} = {acc}\")\n",
    "    return acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.0\tTest Accuracy = 8874 / 10000 = 0.8874\n",
      "Epsilon: 0.05\tTest Accuracy = 7560 / 10000 = 0.756\n",
      "Epsilon: 0.1\tTest Accuracy = 5786 / 10000 = 0.5786\n",
      "Epsilon: 0.15\tTest Accuracy = 3945 / 10000 = 0.3945\n",
      "Epsilon: 0.2\tTest Accuracy = 2239 / 10000 = 0.2239\n",
      "Epsilon: 0.25\tTest Accuracy = 776 / 10000 = 0.0776\n",
      "Epsilon: 0.3\tTest Accuracy = 207 / 10000 = 0.0207\n"
     ]
    }
   ],
   "source": [
    "list_examples = []\n",
    "list_accuracies = []\n",
    "\n",
    "all_epsilons = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "\n",
    "\"\"\"Execute the attacks !!\"\"\"\n",
    "for eps in all_epsilons:\n",
    "    final_acc, adv_examples = fgsm_attack(net, test_loader, eps)\n",
    "    list_examples.append(adv_examples)\n",
    "    list_accuracies.append(final_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Test examples \"\"\"\n",
    "plt.imshow(adv_examples[3][2].detach().numpy().reshape((28, 28)))\n",
    "pred = net.nn(torch.flatten(net.conv(adv_examples[3][2])))\n",
    "pred.argmax()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
