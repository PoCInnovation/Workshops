{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qnyTxjK_GbOD"
   },
   "source": [
    "# An example of Computer Vision\n",
    "\n",
    "In the previous notebook, you created a neural network that can predict the price of a house. Of course, this was exaggerated because it would have been easier to write the function Y = 50x + 50 directly, instead of creating a machine learning model.\n",
    "\n",
    "But what if the rules that define a dataset are more complicated, like a computer vision problem for example? Imagine the scenario where you can recognize different types of clothes, trained from a dataset containing 10 different types.\n",
    "\n",
    "For this, we will use the Fashion MNIST dataset. https://www.kaggle.com/zalando-research/fashionmnist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H41FYgtlHPjW"
   },
   "source": [
    "## Let's go for the code!\n",
    "\n",
    "Start by importing Tensorflow. You will need version 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1577,
     "status": "ok",
     "timestamp": 1550587660097,
     "user": {
      "displayName": "Laurence Moroney",
      "photoUrl": "https://lh3.googleusercontent.com/-RcxktLY-TBk/AAAAAAAAAAI/AAAAAAAAABY/b4V4dTIqmPI/s64/photo.jpg",
      "userId": "06401446828348966425"
     },
     "user_tz": 480
    },
    "id": "q3KzJyjv3rnA",
    "outputId": "7a1ceed7-66f6-4a43-b3f4-26d54bd95817"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_n1U5do3u_F"
   },
   "source": [
    "The Fashion MNIST dataset is available directly from the Keras API tf.keras. You can load it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PmxkHFpt31bM"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GuoLQQBT4E-_"
   },
   "source": [
    "Calling the load_data method on this object will give you 2 sets of 2 lists. These are the train and test values corresponding to the images of garments and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1381,
     "status": "ok",
     "timestamp": 1550587667916,
     "user": {
      "displayName": "Laurence Moroney",
      "photoUrl": "https://lh3.googleusercontent.com/-RcxktLY-TBk/AAAAAAAAAAI/AAAAAAAAABY/b4V4dTIqmPI/s64/photo.jpg",
      "userId": "06401446828348966425"
     },
     "user_tz": 480
    },
    "id": "BTdRgExe4TRB",
    "outputId": "104aab14-aa09-4ed2-806c-38807fbac030"
   },
   "outputs": [],
   "source": [
    "(train_X, train_Y), (test_X, test_Y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rw395ROx4f5Q"
   },
   "source": [
    "What do these values look like? Display a train image and its label to see.\n",
    "Experiment with changing array indices. For example, you can see index 42, this is a different boot than index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1550587722332,
     "user": {
      "displayName": "Laurence Moroney",
      "photoUrl": "https://lh3.googleusercontent.com/-RcxktLY-TBk/AAAAAAAAAAI/AAAAAAAAABY/b4V4dTIqmPI/s64/photo.jpg",
      "userId": "06401446828348966425"
     },
     "user_tz": 480
    },
    "id": "FPc9d3gJ3jWF",
    "outputId": "5efae963-162d-4418-c001-2e8d6af83f40"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_X[0], cmap='gray')\n",
    "print(train_Y[0])\n",
    "print(train_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cbrdH225_nH"
   },
   "source": [
    "You will notice that all the values of the array are numbers between 0 and 255. You will have to normalize them in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRH19pWs6ZDn"
   },
   "outputs": [],
   "source": [
    "train_X  = train_X / 255.0\n",
    "test_X = test_X / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dIn7S9gf62ie"
   },
   "source": [
    "You can now create your model. There are a few new concepts here, but don't worry, we'll explain them to you one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7mAyndG3kVlK"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lUcWaiX7MFj"
   },
   "source": [
    "**Sequential**: This defines a SEQUENCE of layers in the neural network.\n",
    "\n",
    "**Flatten**: Remember your images were a square matrix when you displayed them? Flatten will just grab that matrix and convert it to 1D.\n",
    "\n",
    "**Dense**: Adds a layer of neurons\n",
    "\n",
    "Each neuron layer needs an **activation function**.\n",
    "\n",
    "**Relu** is a function that means \"If X>0 then return X, else return 0\" -- so it will only pass values greater than or equal to 0 into the next network layer.\n",
    "\n",
    "**Softmax** retrieves a set of values, and selects the largest number. For example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it will look for the largest value and convert the output to [0,0, 0,0,1,0,0,0,0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c8vbMCqb9Mh6"
   },
   "source": [
    "The next thing to do, now that the model is defined, is to build it. You can do this by calling the compile method and defining an optimizer and a loss function, then you train it by calling **model.fit**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29548,
     "status": "ok",
     "timestamp": 1550587849991,
     "user": {
      "displayName": "Laurence Moroney",
      "photoUrl": "https://lh3.googleusercontent.com/-RcxktLY-TBk/AAAAAAAAAAI/AAAAAAAAABY/b4V4dTIqmPI/s64/photo.jpg",
      "userId": "06401446828348966425"
     },
     "user_tz": 480
    },
    "id": "BLMdl9aP8nQ0",
    "outputId": "91a80606-f0a5-41f0-9d03-91d1ecdc8e17"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_X, train_Y, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-JJMsvSB-1UY"
   },
   "source": [
    "Once the training has been completed, you should see the accuracy at the end of each epoch. It should be a value like 0.9091. This means that your neural network can classify your train data with around 91% accuracy. It's not the best result we can have, but it's pretty good considering the low number of epochs that has been defined and the speed of the training.\n",
    "\n",
    "But what performance did the model achieve on unknown data ? That's why we have the test images. You can use model.evaluate to evaluate your model on your test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 832,
     "status": "ok",
     "timestamp": 1550587895553,
     "user": {
      "displayName": "Laurence Moroney",
      "photoUrl": "https://lh3.googleusercontent.com/-RcxktLY-TBk/AAAAAAAAAAI/AAAAAAAAABY/b4V4dTIqmPI/s64/photo.jpg",
      "userId": "06401446828348966425"
     },
     "user_tz": 480
    },
    "id": "WzlqsEzX9s5P",
    "outputId": "4dd8018a-f3ba-4e5b-e163-3d4f5dd12f19"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6tki-Aro_Uax"
   },
   "source": [
    "For us, it returned an accurary of 0.8759, which means it's about 88% accurate. As expected, it's less specific about data its never seen.\n",
    "\n",
    "To further understand the different parameters, try the following exploration exercises:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "htldZNWcIPSN"
   },
   "source": [
    "# Exploration exercises\n",
    "\n",
    "These exercises don't really require you to code. Just sometimes change a few values so that you better understand the different parameters given to functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rquQqIx4AaGR"
   },
   "source": [
    "### Exercise 1:\n",
    "\n",
    "For this first exercise, run the following cell: it creates a set of classifications for each image in the test dataset. Then display the first classifications entry. The output corresponds to a list of values. What do you think ? In your opinion, what do these values represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RyEIki0z_hAD"
   },
   "outputs": [],
   "source": [
    "classifications = model.predict(test_X)\n",
    "\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdzqbQhRArzm"
   },
   "source": [
    "Hint: try running `print(test_Y[0])`, and you'll get a 9. Does that help you understand the usefulness of this list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WnBGOrMiA1n5"
   },
   "outputs": [],
   "source": [
    "print(test_Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uUs7eqr7uSvs"
   },
   "source": [
    "### Quiz: What does this list represent?\n",
    "\n",
    "\n",
    "1. This is 10 random values\n",
    "2. These are the first 10 classifications that the computer made\n",
    "3. This is the probability that the item is in each of the 10 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAbr92RTA67u"
   },
   "source": [
    "#### Answer:\n",
    "The correct answer is 3.\n",
    "\n",
    "The output of the model is a list of 10 numbers. These numbers correspond to the probabilities that the value being classified matches the class. The first value in the list is the probability that the image matches class 0, the next class 1, and so on.\n",
    "\n",
    "For our case, the value displayed to us is a 9 because it has the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CD4kC6TBu-69"
   },
   "source": [
    "### How do you know how this list tells you that the item you are predicting is a boot?\n",
    "\n",
    "\n",
    "1. There is not enough information to answer this question\n",
    "2. The 10th item in the list is the largest, and the boot is represented by the label 9\n",
    "3. The bundle is labeled with 9, and there are 0->9 items in the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-haLncrva5L"
   },
   "source": [
    "### Answer\n",
    "\n",
    "The correct answer is 2. Each list starts with index 0, and the label 9 corresponding to the boot means that it is the 10th class. The list containing the largest value at its tenth element means that the neural network predicted that the given input item was classified as a boot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OgQSIfDSOWv6"
   },
   "source": [
    "## Exercise 2:\n",
    "\n",
    "Now look at the model layers. Experiment with different values for the dense layer with 512 neurons.\n",
    "What different results do you get for loss, training time etc.? ? Why do you think there are these differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GSZSwV5UObQP"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_X, train_Y) ,  (test_X, test_Y) = mnist.load_data()\n",
    "\n",
    "train_X = train_X/255.0\n",
    "test_X = test_X/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(train_X, train_Y, epochs=5)\n",
    "\n",
    "model.evaluate(test_X, test_Y)\n",
    "\n",
    "classifications = model.predict(test_X)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOOEnHZFv5cS"
   },
   "source": [
    "### Question 1. Increase it to 1024 neurons, what is the impact?\n",
    "\n",
    "1. Training takes longer, but is more precise\n",
    "2. Training takes longer, but does not impact accuracy\n",
    "3. Training takes the same time, but is more precise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U73MUP2lwrI2"
   },
   "source": [
    "#### Answer\n",
    "\n",
    "The correct answer is answer 1. By adding more neurons, we have more computations, which increases the training time. But in this case you have better accuracy. However, this does not mean that 'more is better'. You will have the opportunity to understand this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WtWxK16hQxLN"
   },
   "source": [
    "## Exercise 3:\n",
    "\n",
    "What happens if you remove the Flatten() layer? What do you think training will give you as a result?\n",
    "\n",
    "You will have an error on the shape of the data. Indeed, a layer cannot contain 28x28 neurons, it must rather be flattened, so that this 28x28 is converted into 784x1. Instead of writing all the code yourself, you can directly call Flatten() at the very beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExNxCwhcQ18S"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_X, train_Y) ,  (test_X, test_Y) = mnist.load_data()\n",
    "\n",
    "train_X = train_X/255.0\n",
    "test_X = test_X/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(train_X, train_Y, epochs=5)\n",
    "\n",
    "model.evaluate(test_X, test_Y)\n",
    "\n",
    "classifications = model.predict(test_X)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VqoCR-ieSGDg"
   },
   "source": [
    "## Exercise 4:\n",
    "\n",
    "Analyze the final layer (output layer). Why must it contain 10 neurons? What happens if you put a number other than 10? Try for example with 5\n",
    "\n",
    "You get an error directly. Indeed, your labels correspond to 10 classes or one neuron per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMckVntcSPvo"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_X, train_Y) ,  (test_X, test_Y) = mnist.load_data()\n",
    "\n",
    "train_X = train_X/255.0\n",
    "test_X = test_X/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(train_X, train_Y, epochs=5)\n",
    "\n",
    "model.evaluate(test_X, test_Y)\n",
    "\n",
    "classifications = model.predict(test_X)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-0lF5MuvSuZF"
   },
   "source": [
    "## Exercise 5:\n",
    "\n",
    "Now try adding additional layers in the network. What happens if you add another layer between the one containing 512 neurons and those containing 10?\n",
    "\n",
    "Answer: There is no significant impact, because it is rather simple data. For more complex data, adding a layer of neurons can be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b1YPa6UhS8Es"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_X, train_Y) ,  (test_X, test_Y) = mnist.load_data()\n",
    "\n",
    "train_X = train_X/255.0\n",
    "test_X = test_X/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(train_X, train_Y, epochs=5)\n",
    "\n",
    "model.evaluate(test_X, test_Y)\n",
    "\n",
    "classifications = model.predict(test_X)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bql9fyaNUSFy"
   },
   "source": [
    "# Exercise 6:\n",
    "\n",
    "Try to train your data with more or less epochs. What do you think of the result?\n",
    "\n",
    "Try with 15 epochs: you will surely have a model with a better loss than the one with 5 epochs\n",
    "\n",
    "Try with 30 epochs: you will see that the loss stops decreasing, and sometimes increases. This is **overfitting**. Track your training, there's no point in continuing to train a model if they've already reached their best performance, right? ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uE3esj9BURQe"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_X, train_Y) ,  (test_X, test_Y) = mnist.load_data()\n",
    "\n",
    "train_X = train_X/255.0\n",
    "test_X = test_X/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(train_X, train_Y, epochs=5)\n",
    "\n",
    "model.evaluate(test_X, test_Y)\n",
    "\n",
    "classifications = model.predict(test_X)\n",
    "\n",
    "print(classifications[34])\n",
    "print(test_Y[34])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7W2PT66ZBHQ"
   },
   "source": [
    "### Exercise 7:\n",
    "\n",
    "Earlier you trained your model with too many epochs and your loss was not changing. You had to wait for the final result, and you thought it would be nice if you could stop training as soon as a certain value was reached. For example, you believe that 95% accuracy is enough for you and if you manage to obtain it after 3 epochs, why expect even more? So how do you stop training? You have... callbacks! Let's watch them in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pkaEHHgqZbYv"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('loss')<0.4):\n",
    "      print(\"\\nAtteint 60% d'accuracy donc on coupe l'entraînement !\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_X, train_Y), (test_X, test_Y) = mnist.load_data()\n",
    "train_X=train_X/255.0\n",
    "test_X=test_X/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(train_X, train_Y, epochs=5, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, head over to `3.handwritten_digits.ipynb` to implement your own model from scratch !"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Course 1 - Part 4 - Lesson 2 - Notebook.ipynb",
   "provenance": [
    {
     "file_id": "1yhyaHJIeyutXBuE2HmViuD-tV5EMqzUG",
     "timestamp": 1547798065395
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
