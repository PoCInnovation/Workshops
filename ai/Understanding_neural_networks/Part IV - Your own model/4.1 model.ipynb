{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 ***Your model***\n",
    "___\n",
    "Well done, you've arrived here ! You now understand key concepts of neural networks and how they are trained, but you haven't created one yet...\n",
    "Don't worry this final task will guide you in recreating a neural network trained to detect any handwritten digit on a 28 by 28 pixel image !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the necessary libs :)\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we need to setup the dataset, we tensorize and noramlize the dataset for simplification. *(You don't need to understand for now just load the dataset, but don't hesistate to ask !)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this code \n",
    "\n",
    "# transfrom and normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# load dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# print info\n",
    "print(f\"Len train dataset : {len(train_dataset)}\")\n",
    "print(f\"Len test  dataset : {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand what's inside this code you can try below to visualise some of the examples !\n",
    "\n",
    "***Don't hesitate to change the NUMBER_OF_ELEMENTS enum to see mutliples examples or no***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of some element of the dataset\n",
    "\n",
    "#TODO: Change the number of elements to display\n",
    "NUMBER_OF_ELEMENTS = ...\n",
    "\n",
    "def imshow(img):\n",
    "    img = img * 0.5 + 0.5  # Denormalisation\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "train_loader_vis = torch.utils.data.DataLoader(train_dataset, batch_size=NUMBER_OF_ELEMENTS, shuffle=True)\n",
    "\n",
    "# Random image \n",
    "dataiter = iter(train_loader_vis)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('Labels :', ' '.join(f'{labels[j].item()};' for j in range(NUMBER_OF_ELEMENTS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Create your model ! \n",
    "\n",
    "Now it's the big work... Create your own model **from scratch** !!\n",
    "\n",
    "***Don't hesitate to make it simple the first time and try to implement with more difficult architecture, think about a simple fully connected layer that start with a flatten layer in the first time and recreate more complex model after !***\n",
    "\n",
    "To understand how CNN or FCN (Linear models) each work, please go check the bonus part [here](<../Part I - The Forward Pass/1.1 concept_of_neural_network.ipynb>)\n",
    "\n",
    "Let's try to help you to create this model : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Setup the Learning rate\n",
    "LEARNING_RATE = ...\n",
    "\n",
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = ... # 28*28 -> what you want\n",
    "        self.fc2 = ...\n",
    "        ...\n",
    "        self.fc = ... # what you want -> 10\n",
    "\n",
    "        self.loss = ...\n",
    "        self.optimizer = ... # use self parameters and the learning rate\n",
    "        self.relu = ...\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = ...\n",
    "        ...\n",
    "        return x\n",
    "\n",
    "\n",
    "    def train_model(self, epochs, train_loader):\n",
    "        self.train()  # Training mode\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            start_time = time.time()  # Start time of the epoch\n",
    "            running_loss = 0.0\n",
    "            total_batches = 0\n",
    "\n",
    "            for i, data in enumerate(train_loader): # Enumerate the data, all the dataset\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                #TODO: Implement the training loop\n",
    "                \n",
    "                # Gradient to zero\n",
    "                # Forward pass\n",
    "                # Loss calculation\n",
    "                # Backward pass\n",
    "                # Optimisation step\n",
    "\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                total_batches += 1 # just help for print \n",
    "                # print every 8 mini-batches\n",
    "                if (i + 1) % 8 == 0 or (i + 1) == len(train_loader):\n",
    "                    print(f\"\\rEpochs {epoch + 1}/{epochs} | Lot {i + 1}/{len(train_loader)} | Loss : {loss.item():.4f}\", end='')\n",
    "\n",
    "            \n",
    "            avg_loss = running_loss / len(train_loader)\n",
    "            epoch_time = time.time() - start_time\n",
    "\n",
    "\n",
    "            print(f\"\\nEpochs {epoch + 1}/{epochs} finish | Average Loss : {avg_loss:.4f} | Time : {epoch_time:.2f} seconds\")\n",
    "\n",
    "        # change the model_path if you want\n",
    "        model_path = \"mnist_model.pth\"\n",
    "        print('Training finished, saving model to :', model_path)\n",
    "        torch.save(self.state_dict(), model_path)\n",
    "\n",
    "\n",
    "    def test_model(self, test_loader):\n",
    "        self.eval()  # Evaluation mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Accuracy of the model on {total} images is : {100 * correct / total:.2f}%')\n",
    "\n",
    "    def load_weights(self, model_path):\n",
    "        self.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Model\n",
    "\n",
    "Initialize the model outside the training loop to load it only once. If you want to restart the training with random weights, you can restart this cell. Otherwise, the training will continue from the **`last loss value`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ready to Train Your Model!\n",
    "\n",
    "If you’ve reached this point, you’re now ready to train your model. But before you begin, don’t forget to set up your **BATCH_SIZE** and **EPOCHS**. Let’s clarify what they mean:\n",
    "\n",
    "- *Epochs* represent the number of times your entire dataset will be processed by the model during training. For instance, with a dataset of 60,000 images, setting ***EPOCHS=10*** means that these 60,000 images will be fed into the model 10 times in total, allowing the model to adjust its weights with each pass.\n",
    "\n",
    "\n",
    "- *Batch size* is the number of images processed in each forward pass before calculating the loss and applying backpropagation to update the model's weights. For example, with ***BATCH_SIZE=64***, 64 images are fed into the model simultaneously. After calculating the loss for this batch, backpropagation adjusts the weights based on that batch’s results.\n",
    "\n",
    "For each epoch, your model will process several *batches*, each containing a specified number of images (`batch_size`). The total number of batches per epoch can be calculated with the following formula:\n",
    "\n",
    "$$\n",
    "{\\text{LOT}} = \\frac{\\text{len\\_dataset}}{\\text{batch\\_size}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the datasets, with a batch_size \n",
    "BATCH_SIZE = ...\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "EPOCHS = ...  # Number of epochs\n",
    "\n",
    "# Train the model\n",
    "model.train_model(EPOCHS, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now time to play with other students ! Try to compare which have the best accuracy ! it will be the ***best model*** :)\n",
    "\n",
    "*(try to go as close as 99%)* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test_model(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work in progress\n",
    "\n",
    "# import importlib\n",
    "# import visualizer\n",
    "# import threading\n",
    "# # Recharger le module si nécessaire\n",
    "# importlib.reload(visualizer)\n",
    "\n",
    "# from visualizer import visualize_model\n",
    "\n",
    "# flask_thread = threading.Thread(target=visualize_model, args=(model, 5001))\n",
    "# flask_thread.start()\n",
    "\n",
    "# print(\"Server is running on http://127.0.0.1:5001\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
