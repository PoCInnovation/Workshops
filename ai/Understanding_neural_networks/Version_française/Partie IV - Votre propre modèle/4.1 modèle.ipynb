{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 ***Votre Modèle***\n",
    "___\n",
    "Bravo, vous êtes arrivé jusqu'ici ! Vous comprenez maintenant les concepts clés des réseaux de neurones et leur entraînement, mais vous n'en avez pas encore créé un...\n",
    "Pas de panique, cette tâche finale vous guidera dans la création d'un réseau de neurones entraîné pour détecter n'importe quel chiffre écrit à la main sur une image de 28 par 28 pixels !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importons toutes les librairies nécéssaires:)\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, nous devons préparer le jeu de données : nous tensorions et normalisons le jeu de données pour simplifier le traitement. *(Vous n'avez pas besoin de comprendre cela pour l'instant, chargez simplement le jeu de données, mais n'hésitez pas à poser des questions !)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez simplement ce code\n",
    "\n",
    "# transformation et normalisation des données\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# chargement du jeu de données\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# affichage des informations\n",
    "print(f\"Len train dataset : {len(train_dataset)}\")\n",
    "print(f\"Len test  dataset : {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour comprendre ce que contient ce code, vous pouvez essayer le code ci-dessous pour visualiser certains exemples !\n",
    "\n",
    "***N'hésitez pas à modifier la variable NUMBER_OF_ELEMENTS pour voir plusieurs exemples ou aucun***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de certains éléments du jeu de données\n",
    "\n",
    "# TODO : Changer le nombre d'éléments à afficher\n",
    "NUMBER_OF_ELEMENTS = ...\n",
    "\n",
    "def imshow(img):\n",
    "    img = img * 0.5 + 0.5  # Dénormalisation\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "train_loader_vis = torch.utils.data.DataLoader(train_dataset, batch_size=NUMBER_OF_ELEMENTS, shuffle=True)\n",
    "\n",
    "# Image aléatoire\n",
    "dataiter = iter(train_loader_vis)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('Labels :', ' '.join(f'{labels[j].item()};' for j in range(NUMBER_OF_ELEMENTS)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Créez votre modèle !\n",
    "\n",
    "Voici le gros du travail... Créez votre propre modèle **à partir de zéro** !!\n",
    "\n",
    "***N'hésitez pas à commencer simplement la première fois, puis à essayer d'implémenter une architecture plus complexe. Pensez d'abord à une couche entièrement connectée qui commence par une couche de flattening, et recréez un modèle plus complexe ensuite !***\n",
    "\n",
    "Pour comprendre comment fonctionnent les réseaux de neurones convolutifs (CNN) ou entièrement connectés (FCN, modèles linéaires), allez consulter la partie bonus [ici](<../Partie I - Propagation Avant /1.1 concept_du_reseau_de_neurones.ipynb>).\n",
    "\n",
    "Nous allons essayer de vous aider à créer ce modèle :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Définir le taux d'apprentissage\n",
    "LEARNING_RATE = ...\n",
    "\n",
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = ... # 28*28 -> ce que vous souhaitez\n",
    "        self.fc2 = ...\n",
    "        ...\n",
    "        self.fc = ... # ce que vous souhaitez -> 10\n",
    "\n",
    "        self.loss = ...\n",
    "        self.optimizer = ... # utilisez les paramètres self et le taux d'apprentissage\n",
    "        self.relu = ...\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = ...\n",
    "        ...\n",
    "        return x\n",
    "\n",
    "    def train_model(self, epochs, train_loader):\n",
    "        self.train()  # Mode d'entraînement\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            start_time = time.time()  # Temps de début de l'époque\n",
    "            running_loss = 0.0\n",
    "            total_batches = 0\n",
    "\n",
    "            for i, data in enumerate(train_loader): # Énumère les données, tout le jeu de données\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                # TODO: Implémenter la boucle d'entraînement\n",
    "                \n",
    "                # Gradient mis à zéro\n",
    "                # Passage avant\n",
    "                # Calcul de la perte\n",
    "                # Passage arrière\n",
    "                # Étape d'optimisation\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                total_batches += 1  # juste pour aider à l'affichage\n",
    "                # afficher tous les 8 mini-lots\n",
    "                if (i + 1) % 8 == 0 or (i + 1) == len(train_loader):\n",
    "                    print(f\"\\rÉpoque {epoch + 1}/{epochs} | Lot {i + 1}/{len(train_loader)} | Perte : {loss.item():.4f}\", end='')\n",
    "\n",
    "            avg_loss = running_loss / len(train_loader)\n",
    "            epoch_time = time.time() - start_time\n",
    "\n",
    "            print(f\"\\nÉpoque {epoch + 1}/{epochs} terminée | Perte Moyenne : {avg_loss:.4f} | Temps : {epoch_time:.2f} secondes\")\n",
    "\n",
    "        # changez le chemin model_path si nécessaire\n",
    "        model_path = \"mnist_model.pth\"\n",
    "        print('Entraînement terminé, sauvegarde du modèle à :', model_path)\n",
    "        torch.save(self.state_dict(), model_path)\n",
    "\n",
    "    def test_model(self, test_loader):\n",
    "        self.eval()  # Mode d'évaluation\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Précision du modèle sur {total} images : {100 * correct / total:.2f}%')\n",
    "\n",
    "    def load_weights(self, model_path):\n",
    "        self.load_state_dict(torch.load(model_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialiser le Modèle\n",
    "\n",
    "Initialisez le modèle en dehors de la boucle d'entraînement pour ne le charger qu'une seule fois. Si vous souhaitez recommencer l'entraînement avec des poids aléatoires, vous pouvez redémarrer cette cellule. Sinon, l'entraînement continuera à partir de la **`dernière valeur de perte`**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prêt à Entraîner Votre Modèle !\n",
    "\n",
    "Si vous êtes arrivé jusqu'ici, vous êtes maintenant prêt à entraîner votre modèle. Mais avant de commencer, n'oubliez pas de configurer votre **BATCH_SIZE** et vos **EPOCHS**. Clarifions ce que ces termes signifient :\n",
    "\n",
    "- *Époques* (*Epochs*) représentent le nombre de fois que votre ensemble de données complet sera traité par le modèle pendant l'entraînement. Par exemple, avec un jeu de données de 60 000 images, définir ***EPOCHS=10*** signifie que ces 60 000 images seront passées dans le modèle 10 fois au total, permettant au modèle d'ajuster ses poids à chaque passage.\n",
    "\n",
    "- *Taille de lot* (*Batch size*) est le nombre d'images traitées à chaque passage avant de calculer la perte et d'appliquer la rétropropagation pour mettre à jour les poids du modèle. Par exemple, avec ***BATCH_SIZE=64***, 64 images sont traitées simultanément par le modèle. Après avoir calculé la perte pour ce lot, la rétropropagation ajuste les poids en fonction des résultats de ce lot.\n",
    "\n",
    "Pour chaque époque, votre modèle traitera plusieurs *lots* (*batches*), chacun contenant un nombre spécifié d'images (`batch_size`). Le nombre total de lots par époque peut être calculé avec la formule suivante :\n",
    "\n",
    "$$\n",
    "{\\text{LOT}} = \\frac{\\text{len\\_dataset}}{\\text{batch\\_size}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charge les jeux de données avec une taille de lot (batch_size)\n",
    "BATCH_SIZE = ...\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "EPOCHS = ...  # Nombre d'époques\n",
    "\n",
    "# Entraîner le modèle\n",
    "model.train_model(EPOCHS, train_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est maintenant temps de jouer avec les autres étudiants ! Essayez de comparer qui obtient la meilleure précision ! Ce sera le ***meilleur modèle*** :)\n",
    "\n",
    "*(essayez d'atteindre les 99% de précision)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test_model(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
